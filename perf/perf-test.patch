From 7bc89acae239827e3cf66dcbbc3724ce6bade89a Mon Sep 17 00:00:00 2001
From: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
Date: Fri, 29 Jul 2016 15:35:00 +1200
Subject: [PATCH 1/9] selftest/filter-subunit: --perf-test-output option for
 timing tests

This reduces test output to the time it takes to succeed.

Signed-off-by: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
---
 Makefile                  |  3 +++
 selftest/filter-subunit   | 27 +++++++++++++++++---
 selftest/perf_tests.py    | 40 +++++++++++++++++++++++++++++
 selftest/subunithelper.py | 65 +++++++++++++++++++++++++++++++++++++++++++++++
 selftest/wscript          | 12 ++++++---
 5 files changed, 140 insertions(+), 7 deletions(-)
 create mode 100644 selftest/perf_tests.py

diff --git a/Makefile b/Makefile
index 95681ae..5cc9077 100644
--- a/Makefile
+++ b/Makefile
@@ -16,6 +16,9 @@ uninstall:
 test:
 	$(WAF) test $(TEST_OPTIONS)
 
+perftest:
+	$(WAF) test --perf-test $(TEST_OPTIONS)
+
 help:
 	@echo NOTE: to run extended waf options use $(WAF_BINARY) or modify your PATH
 	$(WAF) --help
diff --git a/selftest/filter-subunit b/selftest/filter-subunit
index 857b842..c3aba73 100755
--- a/selftest/filter-subunit
+++ b/selftest/filter-subunit
@@ -44,6 +44,8 @@ parser.add_option("--fail-on-empty", default=False,
     action="store_true", help="Fail if there was no subunit output")
 parser.add_option("--list", default=False,
     action="store_true", help="Operate in list mode")
+parser.add_option("--perf-test-output", default=False,
+    action="store_true", help="orientate output for performance measurement")
 opts, args = parser.parse_args()
 
 if opts.list:
@@ -51,6 +53,18 @@ if opts.list:
          sys.stdout.write("%s%s%s\n" % (opts.prefix, l.rstrip(), opts.suffix))
     sys.exit(0)
 
+if opts.perf_test_output:
+    bad_options = []
+    for bad_opt in ('fail_immediately', 'strip_passed_output',
+                    'flapping', 'expected_failures'):
+        if getattr(opts, bad_opt):
+            bad_options.append(bad_opt)
+    if bad_options:
+        print >>sys.stderr, ("--perf-test-output is incompatible with --%s" %
+                             (', --'.join(x.replace('_', '-')
+                                          for x in bad_options)))
+        sys.exit(1)
+
 if opts.expected_failures:
     expected_failures = subunithelper.read_test_regexes(opts.expected_failures)
 else:
@@ -76,10 +90,15 @@ def handle_sigint(sig, stack):
 signal.signal(signal.SIGINT, handle_sigint)
 
 out = subunithelper.SubunitOps(sys.stdout)
-msg_ops = subunithelper.FilterOps(out, opts.prefix, opts.suffix, expected_failures,
-    opts.strip_passed_output,
-    fail_immediately=opts.fail_immediately,
-    flapping=flapping)
+
+if opts.perf_test_output:
+    msg_ops = subunithelper.PerfFilterOps(out, opts.prefix, opts.suffix)
+else:
+    msg_ops = subunithelper.FilterOps(out, opts.prefix, opts.suffix,
+                                      expected_failures,
+                                      opts.strip_passed_output,
+                                      fail_immediately=opts.fail_immediately,
+                                      flapping=flapping)
 
 try:
     ret = subunithelper.parse_results(msg_ops, statistics, sys.stdin)
diff --git a/selftest/perf_tests.py b/selftest/perf_tests.py
new file mode 100644
index 0000000..9e0d4ad
--- /dev/null
+++ b/selftest/perf_tests.py
@@ -0,0 +1,40 @@
+#!/usr/bin/python
+
+# This script generates a list of testsuites that should be run to
+# test Samba performance.
+#
+# These tests are not intended to exercise aspect of Samba, but
+# perform common simple functions or to ascertain performance.
+#
+
+# The syntax for a testsuite is "-- TEST --" on a single line, followed
+# by the name of the test, the environment it needs and the command to run, all
+# three separated by newlines. All other lines in the output are considered
+# comments.
+
+from selftesthelpers import *
+
+samba4srcdir = source4dir()
+samba4bindir = bindir()
+
+planpythontestsuite("none", "samba.tests.blackbox.ndrdump")
+plantestsuite(
+    "samba4.blackbox.upgradeprovision.release-4-0-0", "none",
+    ["PYTHON=%s" % python,
+     os.path.join(bbdir, "upgradeprovision-oldrelease.sh"),
+     '$PREFIX_ABS/provision', 'release-4-0-0', configuration])
+plantestsuite(
+    "samba4.blackbox.upgradeprovision.release-4-5-0-pre1", "none",
+    ["PYTHON=%s" % python,
+     os.path.join(bbdir, "dbcheck-oldrelease.sh"),
+     '$PREFIX_ABS/provision', 'release-4-5-0-pre1', configuration])
+planpythontestsuite("none", "samba.tests.upgradeprovision")
+planpythontestsuite("none", "samba.tests.xattr")
+planpythontestsuite("none", "samba.tests.ntacls")
+planpythontestsuite("none", "samba.tests.policy")
+plantestsuite_loadlist("samba4.ldap.vlv.python(ad_dc_ntvfs)", "ad_dc_ntvfs",
+                       [python, os.path.join(samba4srcdir,
+                                             "dsdb/tests/python/vlv.py"),
+                        '$SERVER', '-U"$USERNAME%$PASSWORD"',
+                        '--workgroup=$DOMAIN',
+                        '$LOADLIST', '$LISTOPT'])
diff --git a/selftest/subunithelper.py b/selftest/subunithelper.py
index a3bb30b..5ea74f3 100644
--- a/selftest/subunithelper.py
+++ b/selftest/subunithelper.py
@@ -17,6 +17,7 @@
 
 __all__ = ['parse_results']
 
+import datetime
 import re
 import sys
 from samba import subunit
@@ -429,6 +430,70 @@ class FilterOps(unittest.TestResult):
         self.fail_immediately = fail_immediately
 
 
+class PerfFilterOps(unittest.TestResult):
+
+    def progress(self, delta, whence):
+        pass
+
+    def output_msg(self, msg):
+        pass
+
+    def control_msg(self, msg):
+        pass
+
+    def start_testsuite(self, name):
+        self.suite_has_time = False
+
+    def end_testsuite(self, name, result, reason=None):
+        pass
+
+    def _add_prefix(self, test):
+        return subunit.RemotedTestCase(self.prefix + test.id() + self.suffix)
+
+    def time(self, time):
+        self.latest_time = time
+        #self._ops.output_msg("found time %s\n" % time)
+        self.suite_has_time = True
+
+    def get_time(self):
+        if self.suite_has_time:
+            return self.latest_time
+        return datetime.datetime.utcnow()
+
+    def startTest(self, test):
+        self.seen_output = True
+        test = self._add_prefix(test)
+        self.starts[test.id()] = self.get_time()
+
+    def addSuccess(self, test):
+        test = self._add_prefix(test)
+        tid = test.id()
+        if tid not in self.starts:
+            self._ops.addError(test, "%s succeeded without ever starting!" % tid)
+        delta = self.get_time() - self.starts[tid]
+        self._ops.output_msg("elapsed-time: %s: %f\n" % (tid, delta.total_seconds()))
+
+    def addFailure(self, test, err=''):
+        tid = test.id()
+        delta = self.get_time() - self.starts[tid]
+        self._ops.output_msg("failure: %s failed after %f seconds (%s)\n" %
+                             (tid, delta.total_seconds(), err))
+
+    def addError(self, test, err=''):
+        tid = test.id()
+        delta = self.get_time() - self.starts[tid]
+        self._ops.output_msg("error: %s failed after %f seconds (%s)\n" %
+                             (tid, delta.total_seconds(), err))
+
+    def __init__(self, out, prefix='', suffix=''):
+        self._ops = out
+        self.prefix = prefix
+        self.suffix = suffix
+        self.starts = {}
+        self.seen_output = False
+        self.suite_has_time = False
+
+
 class PlainFormatter(TestsuiteEnabledTestResult):
 
     def __init__(self, verbose, immediate, statistics,
diff --git a/selftest/wscript b/selftest/wscript
index 61ca0bd..04e58d7 100644
--- a/selftest/wscript
+++ b/selftest/wscript
@@ -79,6 +79,8 @@ def set_options(opt):
                   action="store_true", dest='SOCKET_WRAPPER_KEEP_PCAP', default=False)
     gr.add_option('--random-order', dest='RANDOM_ORDER', default=False,
                   action="store_true", help="Run testsuites in random order")
+    gr.add_option('--perf-test', dest='PERF_TEST', default=False,
+                  action="store_true", help="run performance tests only")
 
 def configure(conf):
     conf.env.SELFTEST_PREFIX = Options.options.SELFTEST_PREFIX
@@ -193,9 +195,13 @@ def cmd_testonly(opt):
     if not os.path.isdir(env.SELFTEST_PREFIX):
         os.makedirs(env.SELFTEST_PREFIX, int('755', 8))
 
-    env.TESTLISTS = ('--testlist="${PYTHON} ${srcdir}/selftest/tests.py|" ' +
-                     '--testlist="${PYTHON} ${srcdir}/source3/selftest/tests.py|" ' +
-                     '--testlist="${PYTHON} ${srcdir}/source4/selftest/tests.py|"')
+    if Options.options.PERF_TEST:
+        env.TESTLISTS = '--testlist="${PYTHON} ${srcdir}/selftest/perf_tests.py|" '
+        env.FILTER_OPTIONS += ' --perf-test-output'
+    else:
+        env.TESTLISTS = ('--testlist="${PYTHON} ${srcdir}/selftest/tests.py|" ' +
+                         '--testlist="${PYTHON} ${srcdir}/source3/selftest/tests.py|" ' +
+                         '--testlist="${PYTHON} ${srcdir}/source4/selftest/tests.py|"')
 
     if CONFIG_SET(opt, 'AD_DC_BUILD_IS_ENABLED'):
         env.SELFTEST_TARGET = "samba"
-- 
2.7.4


From e59fd0e74412c3609c66e115264ff0040726a297 Mon Sep 17 00:00:00 2001
From: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
Date: Wed, 3 Aug 2016 16:03:57 +1200
Subject: [PATCH 2/9] blackbox tests: add timestamps for subunut tests

Signed-off-by: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
---
 testprogs/blackbox/subunit.sh | 11 +++++++++++
 1 file changed, 11 insertions(+)

diff --git a/testprogs/blackbox/subunit.sh b/testprogs/blackbox/subunit.sh
index db7fb05..70fe2d7 100755
--- a/testprogs/blackbox/subunit.sh
+++ b/testprogs/blackbox/subunit.sh
@@ -18,14 +18,23 @@
 #  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 #
 
+timestamp() {
+  # mark the start time. With Gnu date, you get nanoseconds from %N
+  # (here truncated to microseconds with %6N), but not on BSDs,
+  # Solaris, etc, which will apparently leave either %N or N at the end.
+  date -u +'time: %Y-%m-%d %H:%M:%S.%6NZ' | sed 's/%\?NZ$/000000Z/'
+}
+
 subunit_start_test () {
   # emit the current protocol start-marker for test $1
+  timestamp
   echo "test: $1"
 }
 
 
 subunit_pass_test () {
   # emit the current protocol test passed marker for test $1
+  timestamp
   echo "success: $1"
 }
 
@@ -38,6 +47,7 @@ subunit_fail_test () {
   # the error text.
   # we use stdin because the failure message can be arbitrarily long, and this
   # makes it convenient to write in scripts (using <<END syntax.
+  timestamp
   echo "failure: $1 ["
   cat -
   echo "]"
@@ -49,6 +59,7 @@ subunit_error_test () {
   # the error text.
   # we use stdin because the failure message can be arbitrarily long, and this
   # makes it convenient to write in scripts (using <<END syntax.
+  timestamp
   echo "error: $1 ["
   cat -
   echo "]"
-- 
2.7.4


From b3b1520d82dca2a861cf4b85e84822fe1f65f3f0 Mon Sep 17 00:00:00 2001
From: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
Date: Wed, 3 Aug 2016 16:13:03 +1200
Subject: [PATCH 3/9] make perftest: remove irrelevant filter options

options like --expected-failures won't work with --perf-test-output


Signed-off-by: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
---
 selftest/wscript | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/selftest/wscript b/selftest/wscript
index 04e58d7..52861df 100644
--- a/selftest/wscript
+++ b/selftest/wscript
@@ -197,7 +197,7 @@ def cmd_testonly(opt):
 
     if Options.options.PERF_TEST:
         env.TESTLISTS = '--testlist="${PYTHON} ${srcdir}/selftest/perf_tests.py|" '
-        env.FILTER_OPTIONS += ' --perf-test-output'
+        env.FILTER_OPTIONS = '${PYTHON} -u ${srcdir}/selftest/filter-subunit  --perf-test-output'
     else:
         env.TESTLISTS = ('--testlist="${PYTHON} ${srcdir}/selftest/tests.py|" ' +
                          '--testlist="${PYTHON} ${srcdir}/source3/selftest/tests.py|" ' +
-- 
2.7.4


From e817cccbff79d7c4881d5c3d0ee047039e549a5a Mon Sep 17 00:00:00 2001
From: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
Date: Wed, 3 Aug 2016 16:27:16 +1200
Subject: [PATCH 4/9] use python for subunit.sh timing

---
 testprogs/blackbox/subunit.sh | 7 +++----
 1 file changed, 3 insertions(+), 4 deletions(-)

diff --git a/testprogs/blackbox/subunit.sh b/testprogs/blackbox/subunit.sh
index 70fe2d7..6923833 100755
--- a/testprogs/blackbox/subunit.sh
+++ b/testprogs/blackbox/subunit.sh
@@ -19,10 +19,9 @@
 #
 
 timestamp() {
-  # mark the start time. With Gnu date, you get nanoseconds from %N
-  # (here truncated to microseconds with %6N), but not on BSDs,
-  # Solaris, etc, which will apparently leave either %N or N at the end.
-  date -u +'time: %Y-%m-%d %H:%M:%S.%6NZ' | sed 's/%\?NZ$/000000Z/'
+  # Yes, it looks like we could use `date +...`, but that doesn't
+  # have sub-second resolution on non-Gnu systems.
+  python -c "import datetime; print datetime.datetime.utcnow().strftime('time: %Y-%m-%d %H:%M:%S.%fZ')"
 }
 
 subunit_start_test () {
-- 
2.7.4


From ff8bece7bf0e15d9090a05197ad1a696c85585f6 Mon Sep 17 00:00:00 2001
From: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
Date: Wed, 3 Aug 2016 17:53:46 +1200
Subject: [PATCH 5/9] begin a samba4 perf test

---
 selftest/perf_tests.py                  |  10 +-
 source4/dsdb/tests/python/perf_tests.py | 212 ++++++++++++++++++++++++++++++++
 2 files changed, 215 insertions(+), 7 deletions(-)
 create mode 100644 source4/dsdb/tests/python/perf_tests.py

diff --git a/selftest/perf_tests.py b/selftest/perf_tests.py
index 9e0d4ad..fd4b819 100644
--- a/selftest/perf_tests.py
+++ b/selftest/perf_tests.py
@@ -19,11 +19,6 @@ samba4bindir = bindir()
 
 planpythontestsuite("none", "samba.tests.blackbox.ndrdump")
 plantestsuite(
-    "samba4.blackbox.upgradeprovision.release-4-0-0", "none",
-    ["PYTHON=%s" % python,
-     os.path.join(bbdir, "upgradeprovision-oldrelease.sh"),
-     '$PREFIX_ABS/provision', 'release-4-0-0', configuration])
-plantestsuite(
     "samba4.blackbox.upgradeprovision.release-4-5-0-pre1", "none",
     ["PYTHON=%s" % python,
      os.path.join(bbdir, "dbcheck-oldrelease.sh"),
@@ -32,9 +27,10 @@ planpythontestsuite("none", "samba.tests.upgradeprovision")
 planpythontestsuite("none", "samba.tests.xattr")
 planpythontestsuite("none", "samba.tests.ntacls")
 planpythontestsuite("none", "samba.tests.policy")
-plantestsuite_loadlist("samba4.ldap.vlv.python(ad_dc_ntvfs)", "ad_dc_ntvfs",
+plantestsuite_loadlist("samba4.ldap.perf_tests.python(ad_dc_ntvfs)",
+                       "ad_dc_ntvfs",
                        [python, os.path.join(samba4srcdir,
-                                             "dsdb/tests/python/vlv.py"),
+                                             "dsdb/tests/python/perf_tests.py"),
                         '$SERVER', '-U"$USERNAME%$PASSWORD"',
                         '--workgroup=$DOMAIN',
                         '$LOADLIST', '$LISTOPT'])
diff --git a/source4/dsdb/tests/python/perf_tests.py b/source4/dsdb/tests/python/perf_tests.py
new file mode 100644
index 0000000..7e37ecc
--- /dev/null
+++ b/source4/dsdb/tests/python/perf_tests.py
@@ -0,0 +1,212 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+import optparse
+import sys
+sys.path.insert(0, 'bin/python')
+
+import os
+import samba
+import samba.getopt as options
+
+from samba.tests.subunitrun import SubunitOptions, TestProgram
+
+from samba.samdb import SamDB
+from samba.auth import system_session
+from ldb import Message, MessageElement, Dn, LdbError
+from ldb import FLAG_MOD_ADD, FLAG_MOD_REPLACE, FLAG_MOD_DELETE
+from ldb import SCOPE_BASE, SCOPE_SUBTREE, SCOPE_ONELEVEL
+
+parser = optparse.OptionParser("perf_tests.py [options] <host>")
+sambaopts = options.SambaOptions(parser)
+parser.add_option_group(sambaopts)
+parser.add_option_group(options.VersionOptions(parser))
+
+# use command line creds if available
+credopts = options.CredentialsOptions(parser)
+parser.add_option_group(credopts)
+opts, args = parser.parse_args()
+subunitopts = SubunitOptions(parser)
+parser.add_option_group(subunitopts)
+
+if len(args) < 1:
+    parser.print_usage()
+    sys.exit(1)
+
+host = args[0]
+
+lp = sambaopts.get_loadparm()
+creds = credopts.get_credentials(lp)
+
+
+class PerfTestException(Exception):
+    pass
+
+
+class UserTests(samba.tests.TestCase):
+
+    def add_if_possible(self, *args, **kwargs):
+        """In these tests sometimes things are left in the database
+        deliberately, so we don't worry if we fail to add them a second
+        time."""
+        try:
+            self.ldb.add(*args, **kwargs)
+        except LdbError:
+            pass
+
+    def setUp(self):
+        super(UserTests, self).setUp()
+        self.lp = lp
+        self.ldb = SamDB(host, credentials=creds,
+                         session_info=system_session(lp), lp=lp)
+        self.base_dn = self.ldb.domain_dn()
+        self.ou = "OU=pid%s,%s" % (os.getpid(), self.base_dn)
+        self.ou_users = "OU=users,%s" % self.ou
+        self.ou_groups = "OU=groups,%s" % self.ou
+        self.ou_computers = "OU=computers,%s" % self.ou
+
+        for dn in (self.ou, self.ou_users, self.ou_groups,
+                   self.ou_computers):
+            self.add_if_possible({
+                "dn": dn,
+                "objectclass": "organizationalUnit"})
+
+    def tearDown(self):
+        super(UserTests, self).tearDown()
+
+    def _prepare_n_groups(self, n):
+        for i in range(n):
+            self.add_if_possible({
+                "dn": "cn=g%d,%s" % (i, self.ou_groups),
+                "objectclass": "group"})
+
+    def _add_users(self, start, end):
+        for i in range(start, end):
+            self.ldb.add({
+                "dn": "cn=u%d,%s" % (i, self.ou_users),
+                "objectclass": "user"})
+
+    def test_0_00_do_nothing(self):
+        # this gives us an idea of the overhead
+        pass
+
+    def test_0_01_adding_users_500(self):
+        self._add_users(0, 500)
+
+    def test_0_02_adding_users_1000(self):
+        self._add_users(500, 1000)
+
+    def test_0_03_adding_users_1500(self):
+        self._add_users(1000, 1500)
+
+    def test_0_04_adding_users_2000(self):
+        self._add_users(1500, 2000)
+
+    def _link_user_and_group(self, u, g):
+        m = Message()
+        m.dn = Dn(self.ldb, "CN=g%d,%s" % (g, self.ou_groups))
+        m["member"] = MessageElement("cn=u%d,%s" % (u, self.ou_users),
+                                     FLAG_MOD_ADD, "member")
+        self.ldb.modify(m)
+
+    def _unlink_user_and_group(self, u, g):
+        user = "cn=u%d,%s" % (u, self.ou_users)
+        group = "CN=g%d,%s" % (g, self.ou_groups)
+        m = Message()
+        m.dn = Dn(self.ldb, group)
+        m["member"] = MessageElement(user, FLAG_MOD_DELETE, "member")
+        self.ldb.modify(m)
+
+    def test_1_01_link_users_667(self):
+        self._prepare_n_groups(5)
+        for i in range(667):
+            g = i % 5
+            self._link_user_and_group(i, g)
+
+    def test_1_02_link_users_1333(self):
+        for i in range(667, 1333):
+            g = i % 5
+            self._link_user_and_group(i, g)
+
+    def test_1_03_link_users_2000(self):
+        for i in range(1333, 2000):
+            g = i % 5
+            self._link_user_and_group(i, g)
+
+    def test_2_01_link_users_again_1000(self):
+        for i in range(1000):
+            g = (i + 1) % 5
+            self._link_user_and_group(i, g)
+
+    def test_2_02_link_users_again_2000(self):
+        for i in range(1000, 2000):
+            g = (i + 1) % 5
+            self._link_user_and_group(i, g)
+
+    def test_3_01_link_users_again_1000_few_groups(self):
+        for i in range(1000):
+            g = (i + 2) % 3
+            if g not in (i % 5, (i + 1) % 5):
+                self._link_user_and_group(i, g)
+
+    def test_3_02_link_users_again_2000_few_groups(self):
+        for i in range(1000, 2000):
+            g = (i + 2) % 3
+            if g not in (i % 5, (i + 1) % 5):
+                self._link_user_and_group(i, g)
+
+    def test_4_01_remove_some_links(self):
+        for i in range(2000):
+            g = (i + 1) % 5
+            self._unlink_user_and_group(i, g)
+
+    def test_4_02_remove_some_more_links(self):
+        for i in range(2000):
+            g = i % 5
+            self._unlink_user_and_group(i, g)
+
+    def test_5_01_adding_users_after_links_2500(self):
+        self._add_users(2000, 2500)
+
+    def test_6_01_relink_users_1000(self):
+        for i in range(1000):
+            g = i % 5
+            self._link_user_and_group(i, g)
+
+    def test_6_02_relink_users_2000(self):
+        for i in range(1000, 2000):
+            g = i % 5
+            self._link_user_and_group(i, g)
+
+    def test_6_03_link_users_2500(self):
+        for i in range(2000, 2500):
+            g = i % 5
+            self._link_user_and_group(i, g)
+            g2 = (i + 1) % 5
+            self._link_user_and_group(i, g2)
+
+    def test_7_01_adding_users_after_relinks_3000(self):
+        self._add_users(2500, 3000)
+
+    def test_8_01_delete_a_group(self):
+        self.ldb.delete("cn=g0,%s" % self.ou_groups)
+
+    def test_9_01_delete_users_1000(self):
+        for i in range(1000):
+            self.ldb.delete("cn=u%d,%s" % (i, self.ou_users))
+
+    def test_9_02_delete_users_2000(self):
+        for i in range(1000, 2000):
+            self.ldb.delete("cn=u%d,%s" % (i, self.ou_users))
+
+    def test_9_03_delete_empty_groups(self):
+        for i in range(1, 5):
+            self.ldb.delete("cn=g%d,%s" % (i, self.ou_groups))
+
+
+if "://" not in host:
+    if os.path.isfile(host):
+        host = "tdb://%s" % host
+    else:
+        host = "ldap://%s" % host
+
+TestProgram(module=__name__, opts=subunitopts)
-- 
2.7.4


From b4f55038775aebbcb08b18ca3165ecab408d5bb2 Mon Sep 17 00:00:00 2001
From: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
Date: Thu, 4 Aug 2016 15:35:46 +1200
Subject: [PATCH 6/9] Add a format-jsubunit-json script

---
 selftest/format-subunit-json | 53 ++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 53 insertions(+)
 create mode 100644 selftest/format-subunit-json

diff --git a/selftest/format-subunit-json b/selftest/format-subunit-json
new file mode 100644
index 0000000..b863750
--- /dev/null
+++ b/selftest/format-subunit-json
@@ -0,0 +1,53 @@
+#!/usr/bin/env python
+# Copyright (C) 2008-2010 Jelmer Vernooij <jelmer@samba.org>
+# Copyright (C) 2016 Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
+# Published under the GNU GPL, v3 or later
+
+import optparse
+import os
+import signal
+import sys
+import json
+
+sys.path.insert(0, "bin/python")
+
+
+def json_formatter(src_f, dest_f):
+    """We're not even pretending to be a TestResult subclass; just read
+    from stdin and look for elapsed-time tags."""
+    results = {}
+
+    for line in src_f:
+        line = line.strip()
+        if line[:14] == 'elapsed-time: ':
+            name, time = line[14:].rsplit(':', 1)
+            results[name] = float(time)
+
+    json.dump(results, dest_f,
+              sort_keys=True, indent=2, separators=(',', ': '))
+
+
+def main():
+    parser = optparse.OptionParser("format-subunit-json [options]")
+    parser.add_option("--verbose", action="store_true",
+                      help="ignored, for compatibility")
+    parser.add_option("--immediate", action="store_true",
+                      help="ignored, for compatibility")
+    parser.add_option("--prefix", type="string", default=".",
+                      help="Prefix to write summary.json to")
+    opts, args = parser.parse_args()
+
+    fn = os.path.join(opts.prefix, "summary.json")
+    f = open(fn, 'w')
+    json_formatter(sys.stdin, f)
+    f.close()
+    print
+    print "A JSON file summarising these tests performance found in:"
+    print " ", fn
+
+
+def handle_sigint(sig, stack):
+    sys.exit(0)
+
+signal.signal(signal.SIGINT, handle_sigint)
+main()
-- 
2.7.4


From 7c2c8d6c3131ad62e42f7085a7b6d5fd3cdd8379 Mon Sep 17 00:00:00 2001
From: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
Date: Thu, 4 Aug 2016 17:19:18 +1200
Subject: [PATCH 7/9] selftest/wscript: use the json formatter with perftest

---
 selftest/wscript | 5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

diff --git a/selftest/wscript b/selftest/wscript
index 52861df..35442f7 100644
--- a/selftest/wscript
+++ b/selftest/wscript
@@ -113,7 +113,10 @@ def cmd_testonly(opt):
 
     env.SUBUNIT_FORMATTER = os.getenv('SUBUNIT_FORMATTER')
     if not env.SUBUNIT_FORMATTER:
-        env.SUBUNIT_FORMATTER = '${PYTHON} -u ${srcdir}/selftest/format-subunit --prefix=${SELFTEST_PREFIX} --immediate'
+        if Options.options.PERF_TEST:
+            env.SUBUNIT_FORMATTER = '${PYTHON} -u ${srcdir}/selftest/format-subunit-json --prefix=${SELFTEST_PREFIX}'
+        else:
+            env.SUBUNIT_FORMATTER = '${PYTHON} -u ${srcdir}/selftest/format-subunit --prefix=${SELFTEST_PREFIX} --immediate'
     env.FILTER_XFAIL = '${PYTHON} -u ${srcdir}/selftest/filter-subunit --expected-failures=${srcdir}/selftest/knownfail --flapping=${srcdir}/selftest/flapping'
 
     if Options.options.FAIL_IMMEDIATELY:
-- 
2.7.4


From 7e45116c3588fa00405ec85da8bcc7b03327d747 Mon Sep 17 00:00:00 2001
From: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
Date: Thu, 4 Aug 2016 17:19:51 +1200
Subject: [PATCH 8/9] selftest/format-subunit-json prints to stderr

---
 selftest/format-subunit-json | 1 +
 1 file changed, 1 insertion(+)

diff --git a/selftest/format-subunit-json b/selftest/format-subunit-json
index b863750..d44918c 100644
--- a/selftest/format-subunit-json
+++ b/selftest/format-subunit-json
@@ -19,6 +19,7 @@ def json_formatter(src_f, dest_f):
 
     for line in src_f:
         line = line.strip()
+        print >>sys.stderr, line
         if line[:14] == 'elapsed-time: ':
             name, time = line[14:].rsplit(':', 1)
             results[name] = float(time)
-- 
2.7.4


From 765a5e2b8098d191e8861d24bccd3d2f7edcc8b8 Mon Sep 17 00:00:00 2001
From: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>
Date: Wed, 10 Aug 2016 14:50:39 +1200
Subject: [PATCH 9/9] rework perf tests to be less ad-hoc

---
 source4/dsdb/tests/python/perf_tests.py | 165 ++++++++++++++++++--------------
 1 file changed, 92 insertions(+), 73 deletions(-)

diff --git a/source4/dsdb/tests/python/perf_tests.py b/source4/dsdb/tests/python/perf_tests.py
index 7e37ecc..82326c0 100644
--- a/source4/dsdb/tests/python/perf_tests.py
+++ b/source4/dsdb/tests/python/perf_tests.py
@@ -7,6 +7,7 @@ sys.path.insert(0, 'bin/python')
 import os
 import samba
 import samba.getopt as options
+import random
 
 from samba.tests.subunitrun import SubunitOptions, TestProgram
 
@@ -37,6 +38,7 @@ host = args[0]
 lp = sambaopts.get_loadparm()
 creds = credopts.get_credentials(lp)
 
+random.seed(1)
 
 class PerfTestException(Exception):
     pass
@@ -73,7 +75,9 @@ class UserTests(samba.tests.TestCase):
     def tearDown(self):
         super(UserTests, self).tearDown()
 
+    n_groups = 0
     def _prepare_n_groups(self, n):
+        self.n_groups = n
         for i in range(n):
             self.add_if_possible({
                 "dn": "cn=g%d,%s" % (i, self.ou_groups),
@@ -89,17 +93,16 @@ class UserTests(samba.tests.TestCase):
         # this gives us an idea of the overhead
         pass
 
-    def test_0_01_adding_users_500(self):
-        self._add_users(0, 500)
+    next_user_id = 0
+    def _test_add_many_users(self, n=1000):
+        s = self.next_user_id
+        e = s + n
+        self._add_users(s, e)
+        self.next_user_id = e
 
-    def test_0_02_adding_users_1000(self):
-        self._add_users(500, 1000)
-
-    def test_0_03_adding_users_1500(self):
-        self._add_users(1000, 1500)
-
-    def test_0_04_adding_users_2000(self):
-        self._add_users(1500, 2000)
+    test_00_01_adding_users_1000 = _test_add_many_users
+    test_00_02_adding_users_2000 = _test_add_many_users
+    test_00_03_adding_users_3000 = _test_add_many_users
 
     def _link_user_and_group(self, u, g):
         m = Message()
@@ -116,91 +119,107 @@ class UserTests(samba.tests.TestCase):
         m["member"] = MessageElement(user, FLAG_MOD_DELETE, "member")
         self.ldb.modify(m)
 
-    def test_1_01_link_users_667(self):
-        self._prepare_n_groups(5)
-        for i in range(667):
-            g = i % 5
-            self._link_user_and_group(i, g)
-
-    def test_1_02_link_users_1333(self):
-        for i in range(667, 1333):
-            g = i % 5
-            self._link_user_and_group(i, g)
-
-    def test_1_03_link_users_2000(self):
-        for i in range(1333, 2000):
+    next_linked_user = 0
+    def _test_link_many_users(self, n=1000, groups=5):
+        self._prepare_n_groups(groups)
+        s = self.next_linked_user
+        e = s + n
+        for i in range(s, e):
             g = i % 5
             self._link_user_and_group(i, g)
-
-    def test_2_01_link_users_again_1000(self):
-        for i in range(1000):
+        self._add_users(s, e)
+        self.next_linked_user = e
+
+    test_01_01_link_users_1000 = _test_link_many_users
+    test_01_02_link_users_2000 = _test_link_many_users
+    test_01_03_link_users_3000 = _test_link_many_users
+
+    next_relinked_user = 0
+    def _test_link_many_users_offset_1(self, n=1000, groups=5):
+        s = self.next_relinked_user
+        e = s + n
+        for i in range(s, e):
             g = (i + 1) % 5
             self._link_user_and_group(i, g)
-
-    def test_2_02_link_users_again_2000(self):
-        for i in range(1000, 2000):
-            g = (i + 1) % 5
-            self._link_user_and_group(i, g)
-
-    def test_3_01_link_users_again_1000_few_groups(self):
-        for i in range(1000):
-            g = (i + 2) % 3
+        self._add_users(s, e)
+        self.next_relinked_user = e
+
+    test_02_01_link_users_again_1000 = _test_link_many_users_offset_1
+    test_02_02_link_users_again_2000 = _test_link_many_users_offset_1
+    test_02_03_link_users_again_3000 = _test_link_many_users_offset_1
+
+    next_linked_user_3 = 0
+    def _test_link_many_users_3_groups(self, n=1000, groups=3):
+        s = self.next_linked_user_3
+        e = s + n
+        self.next_linked_user_3 = e
+        for i in range(s, e):
+            g = (i + 2) % groups
             if g not in (i % 5, (i + 1) % 5):
                 self._link_user_and_group(i, g)
 
-    def test_3_02_link_users_again_2000_few_groups(self):
-        for i in range(1000, 2000):
-            g = (i + 2) % 3
-            if g not in (i % 5, (i + 1) % 5):
-                self._link_user_and_group(i, g)
+    test_03_01_link_users_again_1000_few_groups = _test_link_many_users_3_groups
+    test_03_02_link_users_again_2000_few_groups = _test_link_many_users_3_groups
+    test_03_03_link_users_again_3000_few_groups = _test_link_many_users_3_groups
 
-    def test_4_01_remove_some_links(self):
-        for i in range(2000):
+    next_removed_link_0 = 0
+    def _test_remove_links_0(self, n=1000):
+        s = self.next_removed_link_0
+        e = s + n
+        self.next_removed_link_0 = e
+        for i in range(s, e):
             g = (i + 1) % 5
             self._unlink_user_and_group(i, g)
 
-    def test_4_02_remove_some_more_links(self):
-        for i in range(2000):
-            g = i % 5
-            self._unlink_user_and_group(i, g)
+    test_04_01_remove_some_links_1000 = _test_remove_links_0
+    test_04_02_remove_some_links_2000 = _test_remove_links_0
+    test_04_03_remove_some_links_3000 = _test_remove_links_0
 
-    def test_5_01_adding_users_after_links_2500(self):
-        self._add_users(2000, 2500)
+    # back to using _test_add_many_users
+    test_05_01_adding_users_after_links_4000 = _test_add_many_users
 
-    def test_6_01_relink_users_1000(self):
-        for i in range(1000):
-            g = i % 5
-            self._link_user_and_group(i, g)
+    # reset the link count, to replace the original links
+    def test_06_01_relink_users_1000(self):
+        next_linked_user = 0
+        self._test_link_many_users()
 
-    def test_6_02_relink_users_2000(self):
-        for i in range(1000, 2000):
-            g = i % 5
-            self._link_user_and_group(i, g)
+    test_06_02_link_users_2000 = _test_link_many_users
+    test_06_03_link_users_3000 = _test_link_many_users
 
-    def test_6_03_link_users_2500(self):
-        for i in range(2000, 2500):
-            g = i % 5
-            self._link_user_and_group(i, g)
-            g2 = (i + 1) % 5
-            self._link_user_and_group(i, g2)
+    test_07_01_adding_users_after_links_5000 = _test_add_many_users
 
-    def test_7_01_adding_users_after_relinks_3000(self):
-        self._add_users(2500, 3000)
+    def test_08_01_link_random_users_100_groups(self, n=1000, groups=100):
+        self._prepare_n_groups(groups)
+        for i in range(n):
+            u = random.randrange(self.next_user_id)
+            g = random.randrange(groups)
+            try:
+                self._link_user_and_group(i, g)
+            except LdbError:
+                pass
 
-    def test_8_01_delete_a_group(self):
-        self.ldb.delete("cn=g0,%s" % self.ou_groups)
+    def test_09_01_delete_50_groups(self):
+        for i in range(self.n_groups - 50, self.n_groups):
+            self.ldb.delete("cn=g%d,%s" % (i, self.ou_groups))
+        self.n_groups -= 50
 
-    def test_9_01_delete_users_1000(self):
-        for i in range(1000):
+    def _test_delete_many_users(self, n=1000):
+        e = self.next_user_id
+        s = max(0, e - n)
+        self.next_user_id = s
+        for i in range(s, e):
             self.ldb.delete("cn=u%d,%s" % (i, self.ou_users))
 
-    def test_9_02_delete_users_2000(self):
-        for i in range(1000, 2000):
-            self.ldb.delete("cn=u%d,%s" % (i, self.ou_users))
+    test_10_01_delete_users_5000 = _test_delete_many_users
+    test_10_02_delete_users_4000 = _test_delete_many_users
+    test_10_03_delete_users_3000 = _test_delete_many_users
 
-    def test_9_03_delete_empty_groups(self):
-        for i in range(1, 5):
+    def test_11_01_delete_all_groups(self):
+        for i in range(self.n_groups):
             self.ldb.delete("cn=g%d,%s" % (i, self.ou_groups))
+        self.n_groups = 0
+
+    test_12_01_delete_users_after_groups_2000 = _test_delete_many_users
 
 
 if "://" not in host:
-- 
2.7.4

